{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Camille Chow\n",
    "#ECE 471 Assignment 2\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "BATCH_SIZE = 40\n",
    "NUM_BATCHES = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data():\n",
    "    def __init__(self):\n",
    "        num_samp = 200\n",
    "        sigma = 0.1\n",
    "        np.random.seed(1)           #change after testing\n",
    "\n",
    "        #training data for label 0\n",
    "        self.index = np.arange(num_samp)        \n",
    "        self.t0 = np.random.uniform(.08, 1.8, num_samp)\n",
    "        self.x0 = np.atleast_2d(6 * self.t0 * np.cos(2*np.pi*self.t0) + np.random.normal(0, sigma, num_samp)).T\n",
    "        self.y0 = np.atleast_2d(6 * self.t0 * np.sin(2*np.pi*self.t0) + np.random.normal(0, sigma, num_samp)).T\n",
    "        self.class0 = np.vstack((self.x0, self.y0))\n",
    "        #training data for label 1\n",
    "        self.t1 = np.random.uniform(.08, 1.8, num_samp)\n",
    "        self.x1 = np.atleast_2d(6 * self.t1 * np.cos(2*np.pi*self.t1 + np.pi) + np.random.normal(0, sigma, num_samp)).T\n",
    "        self.y1 = np.atleast_2d(6 * self.t1 * np.sin(2*np.pi*self.t1 + np.pi) + np.random.normal(0, sigma, num_samp)).T\n",
    "        self.class1 = np.vstack((self.x1, self.y1))\n",
    "\n",
    "        self.labels = np.hstack((np.zeros(num_samp), np.ones(num_samp)))\n",
    "        self.coords = np.hstack((self.class0, self.class1))\n",
    "\n",
    "    def get_batch(self):\n",
    "        choices = np.random.choice(self.index, size=BATCH_SIZE)\n",
    "\n",
    "        return self.coords[choices], self.labels[choices]      #flatten????\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):   #takes x in R2 and outputs sigmoid\n",
    "    \n",
    "    layer1_size = 250\n",
    "    layer2_size = 250                        #experiment with layer sizes\n",
    "    \n",
    "    w1 = tf.get_variable('w1', [2, layer1_size], tf.float32, tf.random_normal_initializer())    \n",
    "    b1 = tf.get_variable('b1', [layer1_size], tf.float32, tf.zeros_initializer())\n",
    "    w2 = tf.get_variable('w2', [layer1_size, layer2_size], tf.float32, tf.random_normal_initializer())    \n",
    "    b2 = tf.get_variable('b2', [layer2_size], tf.float32, tf.zeros_initializer())\n",
    "    w3 = tf.get_variable('w3', [layer2_size, 1], tf.float32, tf.random_normal_initializer())    \n",
    "    b3 = tf.get_variable('b3', [], tf.float32, tf.zeros_initializer())                  #other initializers???\n",
    "\n",
    "    #perceptron\n",
    "    layer1 = tf.add(tf.matmul(x, w1), b1)\n",
    "    layer2 = tf.add(tf.matmul(tf.nn.relu(layer1), w2), b2)\n",
    "    out = tf.add(tf.matmul(tf.nn.relu(layer2), w3), b3)\n",
    "                                                                #try other activation functions???\n",
    "    return tf.squeeze(tf.sigmoid(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:04<00:00, 60.45it/s]\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, [BATCH_SIZE,2])\n",
    "t = tf.placeholder(tf.float32, [BATCH_SIZE])\n",
    "logits = f(x)\n",
    "\n",
    "lam = .5                 #experiment here\n",
    "loss = tf.losses.sigmoid_cross_entropy(t, logits) + tf.add_n([lam * tf.nn.l2_loss(v) for v in tf.trainable_variables()])\n",
    "optim = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(loss)        #other optimizers???\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "data = Data()\n",
    "\n",
    "for _ in tqdm(range(0, NUM_BATCHES)):\n",
    "    x_np, t_np = data.get_batch()\n",
    "    loss_np, _ = sess.run([loss, optim], feed_dict={x: x_np, t: t_np})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
